{"cells":[{"cell_type":"code","source":["!pip install torchvision\n","import os\n","import torch\n","import torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASk8Hz-MtUlN","executionInfo":{"status":"ok","timestamp":1745155392431,"user_tz":180,"elapsed":121746,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}},"outputId":"af9aeb05-30d3-4fe1-a613-3014205b6ea2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","import pandas as pd\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n"],"metadata":{"id":"vKfwH7h6rhv4","executionInfo":{"status":"ok","timestamp":1745155392773,"user_tz":180,"elapsed":344,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LxYTR6ONKe8q","executionInfo":{"status":"ok","timestamp":1745155505553,"user_tz":180,"elapsed":16390,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}},"outputId":"4fc24848-d347-4d99-a364-2573891d5d33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Google Drive montado.\n"]}],"source":["import os\n","from google.colab import drive\n","\n","# Verifico si ya esta montado\n","drive_mount_point = \"/content/drive\"\n","if not os.path.ismount(drive_mount_point):\n","    drive.mount(drive_mount_point)\n","    print(\"Google Drive montado.\")\n","else:\n","    print(\"Google Drive ya estaba montado.\")\n"]},{"cell_type":"markdown","source":["### Descargo el dataset original y agrego imágenes aumentadas donde ya esté el original"],"metadata":{"id":"iP4LmgmrsUPg"}},{"cell_type":"code","source":["import kagglehub\n","import zipfile\n","import os\n","import shutil\n","\n","# Se Descarga dataset original\n","path = kagglehub.dataset_download(\"kneroma/tacotrashdataset\")\n","print(\"Dataset original descargado en:\", path)\n","\n","# Carpeta donde va a ir el dataset aumentado\n","augmented_dataset_dir = '/content/augmented_dataset'\n","os.makedirs(augmented_dataset_dir, exist_ok=True)\n","\n","original_data_path = os.path.join(augmented_dataset_dir, 'data')\n","shutil.copytree(path, original_data_path)\n","print(\"Carpeta de datos detectada:\", original_data_path)\n","\n","augmented_zip_path = \"/content/drive/MyDrive/VC2/augmented.zip\"\n","\n","with zipfile.ZipFile(augmented_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(original_data_path)\n","\n","print(f\"Dataset aumentado descomprimido en: {original_data_path}\")"],"metadata":{"id":"x0deLnoNhV0C","executionInfo":{"status":"aborted","timestamp":1745155485645,"user_tz":180,"elapsed":39,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Ruta donde estan las carpetas aumentadas\n","augmented_batches_root = \"/content/augmented_dataset/data/kaggle/working\"\n","\n","# Ruta de destino\n","target_data_dir = \"/content/augmented_dataset/data/data\"\n","\n","# Muevo carpetas que empiecen con \"aug_\"\n","for folder in os.listdir(augmented_batches_root):\n","    source = os.path.join(augmented_batches_root, folder)\n","    destination = os.path.join(target_data_dir, folder)\n","\n","    if os.path.isdir(source) and folder.startswith(\"aug_\"):\n","        shutil.move(source, destination)\n","        print(f\"Movido: {folder}\")\n","\n","print(\"Todas las carpetas 'aug_' fueron movidas a la carpeta del dataset original.\")\n"],"metadata":{"id":"0avbgeq3QiND","executionInfo":{"status":"aborted","timestamp":1745155485647,"user_tz":180,"elapsed":41,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}},"collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset combinado"],"metadata":{"id":"0cQhqlgAtjkc"}},{"cell_type":"code","source":["import os\n","import json\n","import pandas as pd\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","import hashlib\n","\n","def stable_int_id(value: str) -> int:\n","    return int(hashlib.sha256(value.encode()).hexdigest(), 16) % (2**31 - 1)\n","\n","\n","class TacoCombinedDataset(Dataset):\n","    def __init__(self,\n","                 image_root,                         # Ruta raíz con todas las imágenes\n","                 annotations_csv_path,               # CSV con todas las anotaciones\n","                 image_map_json_path,                # JSON que mapea image_id -> file_name\n","                 transforms=None):\n","\n","        self.image_root = image_root\n","        self.transforms = transforms\n","\n","        # Lee CSV completo\n","        self.annotations_df = pd.read_csv(annotations_csv_path)\n","\n","        # Carga el mapeo de IDs a file_names\n","        with open(image_map_json_path, 'r') as f:\n","            self.image_map = json.load(f)\n","\n","        # Agrupa anotaciones por ID\n","        self.anns_by_image_id = self.annotations_df.groupby(\"image_id\")\n","\n","        # Mapea cada ID a la ruta del archivo correspondiente\n","        self.image_id_to_path = {}\n","        for image_id in self.anns_by_image_id.groups.keys():\n","            str_id = str(image_id)\n","            if str_id in self.image_map:\n","                file_name = self.image_map[str_id][\"file_name\"]\n","\n","                # Busca imagen con tolerancia a mayúsculas/minúsculas en extensiones y paths parciales\n","                filename_from_json = self.image_map[str(image_id)][\"file_name\"]\n","                target_name_lower = os.path.basename(filename_from_json).lower()\n","\n","                full_path = None\n","                for root, _, files in os.walk(self.image_root):\n","                    for f in files:\n","                        if f.lower() == target_name_lower:\n","                            full_path = os.path.join(root, f)\n","                            break\n","                    if full_path:\n","                        break\n","\n","\n","                # Si no encuentra, probar con otra extensión (.jpg <-> .JPG)\n","                if full_path is None and file_name.lower().endswith('.jpg'):\n","                    alt_ext = '.JPG' if file_name.endswith('.jpg') else '.jpg'\n","                    alt_file_name = file_name[:-4] + alt_ext\n","\n","                    for root, _, files in os.walk(self.image_root):\n","                        if alt_file_name in files:\n","                            full_path = os.path.join(root, alt_file_name)\n","                            break\n","\n","\n","                if full_path and os.path.exists(full_path):\n","                    self.image_id_to_path[image_id] = full_path\n","                else:\n","                    print(f\"⚠️ Imagen no encontrada: {file_name} (id={image_id})\")\n","            else:\n","                print(f\"❌ image_id {image_id} no está en el JSON\")\n","\n","        self.image_ids = list(self.image_id_to_path.keys())\n","        self.classes = self.classes = {0: 'background', **{category_id + 1: category_name for category_name, category_id in zip(self.annotations_df[\"new_category\"].unique(), range(len(self.annotations_df[\"new_category\"].unique())))}}\n","\n","\n","    def __len__(self):\n","        return len(self.image_ids)\n","\n","    def __getitem__(self, idx):\n","        image_id = self.image_ids[idx]\n","        img_path = self.image_id_to_path[image_id]\n","        image = Image.open(img_path).convert(\"RGB\")\n","\n","        anns_df = self.anns_by_image_id.get_group(image_id)\n","        boxes, labels = [], []\n","\n","        for _, row in anns_df.iterrows():\n","            bbox = json.loads(row['bbox']) if isinstance(row['bbox'], str) else row['bbox']\n","            x, y, w, h = bbox\n","            boxes.append([x, y, x + w, y + h])\n","            labels.append(row['category_id'] + 1) #SUMO UNO PORQUE EL 0 ES RESERVADO PARA BACKGROUND\n","\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        labels = torch.as_tensor(labels, dtype=torch.int64)\n","\n","        target = {\n","            \"boxes\": boxes,\n","            \"labels\": labels,\n","            \"image_id\": torch.tensor([stable_int_id(str(image_id))], dtype=torch.int64)\n","        }\n","\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","        return image, target\n"],"metadata":{"id":"Hjprq_5MticU","executionInfo":{"status":"aborted","timestamp":1745155485648,"user_tz":180,"elapsed":41,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defino transformaciones de preentrenamiento"],"metadata":{"id":"G9xQpOl6sZvm"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"2kj7L9MEsNev","executionInfo":{"status":"aborted","timestamp":1745155485651,"user_tz":180,"elapsed":16,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creo dataset"],"metadata":{"id":"lNEpyQdrsd95"}},{"cell_type":"code","source":["dataset = TacoCombinedDataset(\n","    image_root=\"/content/augmented_dataset/data/data\",\n","    annotations_csv_path=\"/content/drive/MyDrive/VC2/augmented_annotations_fixed.csv\",\n","    image_map_json_path=\"/content/drive/MyDrive/VC2/image_map_augmented.json\",\n","    transforms=transform\n"],"metadata":{"id":"WJfKuiWclVao","executionInfo":{"status":"aborted","timestamp":1745155485651,"user_tz":180,"elapsed":215146,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image, target = dataset[0]\n","print(\"Shape:\", image.shape)\n","print(\"Target keys:\", target.keys())\n","print(\"Boxes:\", target[\"boxes\"].shape)\n","print(\"Labels:\", target[\"labels\"])\n"],"metadata":{"id":"ntilkiO9skJM","executionInfo":{"status":"aborted","timestamp":1745155485652,"user_tz":180,"elapsed":215146,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Separo en Train y Val"],"metadata":{"id":"mVSguZc47ETK"}},{"cell_type":"code","source":["from torch.utils.data import random_split, DataLoader\n","\n","train_ratio = 0.8\n","train_size = int(train_ratio * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n","\n"],"metadata":{"id":"n9pzeq3P7Dkj","executionInfo":{"status":"aborted","timestamp":1745155485717,"user_tz":180,"elapsed":1,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Loader"],"metadata":{"id":"lkNTXqu6x2ol"}},{"cell_type":"code","source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=2)\n"],"metadata":{"id":"0gkAPbDYx2Xo","executionInfo":{"status":"aborted","timestamp":1745155485718,"user_tz":180,"elapsed":2,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, targets = next(iter(train_loader))\n","print(\"Nuevo batch size:\", len(images))\n","print(\"Shape imagen 0:\", images[0].shape)\n","print(\"Keys del target:\", targets[0].keys())\n"],"metadata":{"id":"3dXBSk4lx6BP","executionInfo":{"status":"aborted","timestamp":1745155485720,"user_tz":180,"elapsed":215213,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Importar RetinaNet y configurar modelo"],"metadata":{"id":"aOGk6FsZzec5"}},{"cell_type":"code","source":["from torchvision.models.detection import retinanet_resnet50_fpn\n","from torchvision.models.detection.retinanet import RetinaNetClassificationHead, RetinaNet_ResNet50_FPN_Weights\n","\n","# Se carga modelo preentrenado\n","weights = RetinaNet_ResNet50_FPN_Weights.DEFAULT\n","model = retinanet_resnet50_fpn(weights=weights)\n","\n","\n","# Se reemplaza la cabeza de clasificacion con la cantidad correcta de clases\n","num_classes = len(dataset.classes) + 1  # +1 para el background\n","in_features = model.head.classification_head.conv[0][0].in_channels\n","num_anchors = model.head.classification_head.num_anchors\n","\n","model.head.classification_head = RetinaNetClassificationHead(\n","    in_channels=in_features,\n","    num_anchors=num_anchors,\n","    num_classes=num_classes\n",")\n"],"metadata":{"id":"ubrBMG90zeAA","executionInfo":{"status":"aborted","timestamp":1745155485735,"user_tz":180,"elapsed":215227,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preparar dispositivo, optimizador y carpeta de checkpoints"],"metadata":{"id":"eCGio1-DzhIx"}},{"cell_type":"code","source":["import torch.optim as optim\n","import os\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Carpeta para guardar checkpoints\n","checkpoint_dir = \"/content/drive/MyDrive/checkpoints_retinanet_datauag\"\n","os.makedirs(checkpoint_dir, exist_ok=True)\n"],"metadata":{"id":"mc7i8uHvzlEj","executionInfo":{"status":"aborted","timestamp":1745155485736,"user_tz":180,"elapsed":215228,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cargar checkpoint si lo hay"],"metadata":{"id":"N9fsy3zq8ZV9"}},{"cell_type":"code","source":["import os\n","import glob\n","\n","# Inicializa listas de tracking\n","train_losses_per_epoch = []\n","val_losses_per_epoch = []\n","\n","# Busca checkpoints existentes\n","checkpoint_files = sorted(glob.glob(os.path.join(checkpoint_dir, \"retinanet_epoch*_batch*.pth\")))\n","\n","if checkpoint_files:\n","    latest_checkpoint = checkpoint_files[-1]\n","    checkpoint = torch.load(latest_checkpoint, map_location=device)\n","\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","    start_epoch = checkpoint[\"epoch\"]\n","\n","    print(f\"Checkpoint cargado desde: {latest_checkpoint}\")\n","    print(f\"Retomando desde la epoch {start_epoch}\")\n","\n","else:\n","    start_epoch = 0\n","    print(\"No se encontraron checkpoints previos. Comenzando desde cero.\")\n"],"metadata":{"id":"6prbfD3S8ZDA","executionInfo":{"status":"aborted","timestamp":1745155485736,"user_tz":180,"elapsed":215227,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loop de entrenamiento con guardado por batch"],"metadata":{"id":"CpwQVdyIzokW"}},{"cell_type":"code","source":["import os\n","import torch\n","import glob\n","\n","num_epochs = 50\n","start_epoch = 0\n","best_val_loss = float(\"inf\")\n","save_every_n_batches = 50\n","\n","checkpoint_dir = \"checkpoints\"\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","# Listas para graficar despues\n","train_losses_per_epoch = []\n","val_losses_per_epoch = []\n","\n","# Entrenamiento\n","for epoch in range(start_epoch, num_epochs):\n","    model.train()\n","    epoch_loss = 0.0\n","\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        images = [img.to(device) for img in images]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        epoch_loss += losses.item()\n","\n","        if (batch_idx + 1) % save_every_n_batches == 0:\n","            checkpoint_path = os.path.join(\n","                checkpoint_dir,\n","                f\"retinanet_epoch{epoch+1}_batch{batch_idx+1}.pth\"\n","            )\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'batch': batch_idx + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': epoch_loss,\n","            }, checkpoint_path)\n","            print(f\"Checkpoint guardado: epoch {epoch+1}, batch {batch_idx+1}\")\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f}\")\n","    train_losses_per_epoch.append(epoch_loss)\n","\n","    # Validacion\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for images, targets in val_loader:\n","            images = [img.to(device) for img in images]\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","            # Me Aseguro de que sea un dict (como en entrenamiento)\n","            output = model(images, targets)\n","            if isinstance(output, dict):\n","                losses = sum(loss for loss in output.values())\n","                val_loss += losses.item()\n","            else:\n","                print(\"Advertencia: el modelo devolvió algo inesperado en evaluación.\")\n","\n","\n","    val_loss /= len(val_loader)\n","    val_losses_per_epoch.append(val_loss)\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pth\"))\n","        print(f\"Mejor modelo actualizado (Val Loss: {val_loss:.4f})\")\n","\n","    # Borro checkpoints de batches al finalizar la epoch\n","    batch_ckpts = glob.glob(os.path.join(checkpoint_dir, f\"retinanet_epoch{epoch+1}_batch*.pth\"))\n","    for ckpt_file in batch_ckpts:\n","        os.remove(ckpt_file)\n","    print(f\"Checkpoints de batches eliminados para epoch {epoch+1}\")\n"],"metadata":{"id":"IhXyg7hgzpRT","executionInfo":{"status":"aborted","timestamp":1745155485737,"user_tz":180,"elapsed":215228,"user":{"displayName":"Rama Feichu","userId":"01884311508096332307"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}